{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A0GQWDGtrpX"
   },
   "source": [
    "# Rede Neural de Base Radial (RBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7W_VNPAkFcO"
   },
   "source": [
    "As redes RBF são redes de alimentação direta (feedforward) consistindo de três camadas:\n",
    "\n",
    "\n",
    "1.   **Camada de entrada**: propaga os estímulos\n",
    "2.   **Camada escondida**: Unidades de processamento localmente sintonizáveis, utilizando mapeamento não linear.\n",
    "3.   **Camada de saída**: Unidades de processamento lineares.\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "**O treinamento dessa rede ocorre de forma híbrida**, combinando aprendizagem não supervisionada (ANS) com a supervisionada(AS). Isso ocorre, pois em geral não se sabe quais saídas se desejam para a camada escondida. Sendo assim, a distribuição de trabalhos ocorre:\n",
    "*   **ANS**: Treina a camada escondida definindo seus parâmetros livres (centros, larguras dos campos receptivos e pesos).\n",
    "*   **AS**: Determina os valores dos pesos entre as camadas escondidas e de saída, considerando constantes os parâmetros já definidos.\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "**O aprendizado consiste em** determinar os valores para:\n",
    "*   centro das funções de base radial,\n",
    "*   largura das funções,\n",
    "*   pesos da camada de saída.\n",
    "\n",
    "\n",
    "Além disso, para cada neurônio da camada escondida, ele computa uma função de base radial.\n",
    "\n",
    "\n",
    "Os passos necessários são:\n",
    "1.   Utilizar um algoritmo ANS para encontrar os centros (protótipo para um cluster) das RBF;\n",
    "2.   Utilizar métodos heurísticos para determinar a largura (área de influência de um cluster) de cada função;\n",
    "3.   Utilizar um AS para determinar os pesos da camada de saída da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOIor4J3PFBL"
   },
   "source": [
    "1ª Etapa: Inicialização dos grupos com K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHWuP3AXjvq1",
    "outputId": "e544e7fc-6f1e-43fc-fce3-382627b965c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'redes_neurais_pos'...\n",
      "remote: Enumerating objects: 120, done.\u001b[K\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
      "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
      "remote: Total 120 (delta 11), reused 1 (delta 0), pack-reused 90 (from 1)\u001b[K\n",
      "Receiving objects: 100% (120/120), 16.66 MiB | 388.00 KiB/s, done.\n",
      "Resolving deltas: 100% (35/35), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/valmirf/redes_neurais_pos.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ulVaA8RPSwo"
   },
   "source": [
    "Definição da função de base radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YeqYYe9hPY4v"
   },
   "outputs": [],
   "source": [
    "#função de base radial gaussiana\n",
    "def rbfGaussiana(x, c, s):\n",
    "    return np.exp(-1 / (2 * s**2) * (x-c)**2)\n",
    "\n",
    "def rbfMultiquadratica(x, c, s):\n",
    "    return 1 / np.sqrt((x - c) ** 2 + s ** 2)\n",
    "\n",
    "#função de cálculo da largura do campo receptivo em que se repete o mesmo valor pra todos os neurônios\n",
    "def computeEqualStds(centers,k):\n",
    "  dist = [np.sqrt(np.sum((c1 - c2) ** 2)) for c1 in centers for c2 in centers]\n",
    "  dMax = np.max(dist)\n",
    "  stds = np.repeat(dMax / np.sqrt(2 * k), k)\n",
    "  return stds\n",
    "\n",
    "def computeIndividualStds(centers):\n",
    "    stds = []\n",
    "    for i, c1 in enumerate(centers):\n",
    "        distances = [np.linalg.norm(c1 - c2) for j, c2 in enumerate(centers) if i != j] #calcula a distancia media entre o centro c1 e todos os outros centros\n",
    "        stds.append(np.mean(distances))  #media das distancias como largura\n",
    "    return np.array(stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkrFhNWPLq41"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52oUNimoPuK3"
   },
   "source": [
    "2ª Etapa - Treinamento de uma Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RGdrOhYfPzBu"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "class RBFNet(object):\n",
    "    \"\"\"Implementation of a Radial Basis Function Network\"\"\"\n",
    "\n",
    "    def __init__(self, k=3, attnumber=4, lr=0.01, epochs=100, rbf=rbfMultiquadratica, computeStds=computeIndividualStds):\n",
    "        self.k = k  # grupos ou numero de neuronios na camada escondida\n",
    "        self.lr = lr # taxa de aprendizagem\n",
    "        self.epochs = epochs  # número de iterações\n",
    "        self.rbf = rbf # função de base radial\n",
    "        self.computeStds = computeStds  #função de cálculo da largura do campo receptivo\n",
    "\n",
    "        self.w = np.random.randn(self.k,attnumber)\n",
    "        self.b = np.random.randn(1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.stds = []\n",
    "        #K-Means pra pegar os centros inicias\n",
    "        #1º parâmetro da rede RBF\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=self.k, init='random',\n",
    "            n_init=10, max_iter=300).fit(X)\n",
    "        self.centers = kmeans.cluster_centers_\n",
    "        #print('centers: ', self.centers)\n",
    "\n",
    "        #Cálculo la dargura do campo receptivo\n",
    "        #2º parâmetro da rede RBF\n",
    "        #self.stds = self.computeStds(self.centers)\n",
    "        if self.computeStds == computeEqualStds:\n",
    "            self.stds = self.computeStds(self.centers, self.k)\n",
    "        else:\n",
    "            self.stds = self.computeStds(self.centers)\n",
    "\n",
    "        # training\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                # forward pass\n",
    "                #calcula a saída de cada neurônio da função de base radial\n",
    "                phi = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
    "                #calcula somatório do produto da saída da função de base radial e os pesos\n",
    "                F = phi.T.dot(self.w)\n",
    "                F = np.sum(F) + self.b\n",
    "                #saída da rede\n",
    "                out = 0 if F < 0 else 1\n",
    "\n",
    "                #função de perda\n",
    "                loss = (y[i] - out).flatten() ** 2\n",
    "                #print('Loss: {0:.2f}'.format(loss[0]))\n",
    "\n",
    "                #cálculo do erro\n",
    "                error = (y[i] - out).flatten()\n",
    "                #atualização dos pesos\n",
    "                #3º Parâmetro da rede\n",
    "                self.w = self.w + self.lr * error * phi\n",
    "                self.b = self.b + self.lr * error\n",
    "\n",
    "    #calcula saída da rede RBF com a rede treinada\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        error = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            a = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
    "            F = a.T.dot(self.w)\n",
    "            F = np.sum(F) + self.b\n",
    "            out = 0 if F < 0 else 1\n",
    "            y_pred.append(out)\n",
    "\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWNpEtxSW46Q"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# Isto está formatado como código\n",
    "```\n",
    "\n",
    "# Executando a rede neural RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P75CdFJ4W7mU",
    "outputId": "ba28be14-eb7b-4627-c86a-c6b97ddf8708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de erro com 3 neuronios escondidos: 0.3117\n",
      "Taxa de erro com 5 neuronios escondidos: 0.2143\n",
      "Taxa de erro com 7 neuronios escondidos: 0.3442\n",
      "Taxa de erro com 9 neuronios escondidos: 0.2857\n",
      "\n",
      "Número de neurônios escondidos: 3\n",
      "RBF: rbfGaussiana, Método Largura: computeEqualStds, Taxa de erro: 0.2792\n",
      "RBF: rbfGaussiana, Método Largura: computeIndividualStds, Taxa de erro: 0.2338\n",
      "RBF: rbfMultiquadratica, Método Largura: computeEqualStds, Taxa de erro: 0.3117\n",
      "RBF: rbfMultiquadratica, Método Largura: computeIndividualStds, Taxa de erro: 0.2273\n",
      "\n",
      "Número de neurônios escondidos: 5\n",
      "RBF: rbfGaussiana, Método Largura: computeEqualStds, Taxa de erro: 0.2857\n",
      "RBF: rbfGaussiana, Método Largura: computeIndividualStds, Taxa de erro: 0.2208\n",
      "RBF: rbfMultiquadratica, Método Largura: computeEqualStds, Taxa de erro: 0.3312\n",
      "RBF: rbfMultiquadratica, Método Largura: computeIndividualStds, Taxa de erro: 0.2208\n",
      "\n",
      "Número de neurônios escondidos: 7\n",
      "RBF: rbfGaussiana, Método Largura: computeEqualStds, Taxa de erro: 0.2143\n",
      "RBF: rbfGaussiana, Método Largura: computeIndividualStds, Taxa de erro: 0.3442\n",
      "RBF: rbfMultiquadratica, Método Largura: computeEqualStds, Taxa de erro: 0.3442\n",
      "RBF: rbfMultiquadratica, Método Largura: computeIndividualStds, Taxa de erro: 0.3442\n",
      "\n",
      "Número de neurônios escondidos: 9\n",
      "RBF: rbfGaussiana, Método Largura: computeEqualStds, Taxa de erro: 0.2208\n",
      "RBF: rbfGaussiana, Método Largura: computeIndividualStds, Taxa de erro: 0.3182\n",
      "RBF: rbfMultiquadratica, Método Largura: computeEqualStds, Taxa de erro: 0.3312\n",
      "RBF: rbfMultiquadratica, Método Largura: computeIndividualStds, Taxa de erro: 0.3442\n",
      "\n",
      "Melhor configuração encontrada:\n",
      "Neurônios escondidos: 7\n",
      "Função de Base Radial: rbfGaussiana\n",
      "Método de Cálculo da Largura: computeEqualStds\n",
      "Taxa de erro: 0.2143\n"
     ]
    }
   ],
   "source": [
    "# Neste código vou utilizar o pandas, framework amplamente utilizado pra lidar com dados\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#carrega a base de dados e retorna conjuntos de treinamento e teste\n",
    "def load_data():\n",
    "    url = 'redes_neurais_pos/RBF/diabetes.csv'\n",
    "    df = pd.read_csv(url)\n",
    "    #remove a ultima coluna (dados)\n",
    "    data = df[df.columns[:-1]]\n",
    "    #normaliza os dados\n",
    "    normalized_data = (data - data.min()) / (data.max() - data.min())\n",
    "    #retorna a última coluna (rótulos)\n",
    "    labels = df[df.columns[-1]]\n",
    "    #separa em conjunto de treinamento e teste com seus respectivos rótulos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(normalized_data, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#chama função que carrega base de dados\n",
    "#chama função que carrega base de dados\n",
    "training_inputs, test_inputs, training_labels, test_labels = load_data()\n",
    "\n",
    "# Verifica o número de atributos\n",
    "attnumber = training_inputs.shape[1]  # Número de atributos\n",
    "\n",
    "#transforma rótulos do conjunto de treinamento em numeros pra calculo do erro\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(training_labels.values)\n",
    "training_labels_transformed = le.transform(training_labels.values)\n",
    "\n",
    "# CODIGO DA QUESTAO 1\n",
    "neurons_options = [3, 5, 7, 9] #neurônios escondidos\n",
    "errors = {}\n",
    "\n",
    "for k in neurons_options:\n",
    "    rbfnet = RBFNet(lr=1e-2, attnumber=attnumber, k=k, computeStds=computeEqualStds)\n",
    "    rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
    "\n",
    "    # aqui transformamos os rotulos do conjunto de teste em numeros para calculo do erro\n",
    "    test_labels_transformed = le.transform(test_labels.values)\n",
    "    y_pred = rbfnet.predict(test_inputs.values)\n",
    "\n",
    "    errorabs = abs(test_labels_transformed - y_pred)\n",
    "    error_rate = np.sum(errorabs) / len(test_labels_transformed)\n",
    "    errors[k] = error_rate\n",
    "    print(f'Taxa de erro com {k} neuronios escondidos: {error_rate:.4f}')\n",
    "\n",
    "\n",
    "# CODIGO DA QUESTAO 2\n",
    "#Usando a melhor configuração de 9 neurônios escondidos\n",
    "# k = 9\n",
    "# rbfnet = RBFNet(lr=1e-2, attnumber=attnumber, k=k, computeStds=computeIndividualStds)\n",
    "# rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
    "\n",
    "# # Transforma rótulos do conjunto de teste em números para cálculo do erro\n",
    "# test_labels_transformed = le.transform(test_labels.values)\n",
    "# y_pred = rbfnet.predict(test_inputs.values)\n",
    "\n",
    "# errorabs = abs(test_labels_transformed - y_pred)\n",
    "# error_rate = np.sum(errorabs) / len(test_labels_transformed)\n",
    "\n",
    "# print(f'Taxa de erro com larguras individuais: {error_rate:.4f}')\n",
    "\n",
    "#CODIGO DA QUESTAO 3\n",
    "# Define as configurações para combinar\n",
    "rbf_functions = [rbfGaussiana, rbfMultiquadratica]\n",
    "std_methods = [computeEqualStds, computeIndividualStds]\n",
    "configurations = [(rbf_func, std_method) for rbf_func in rbf_functions for std_method in std_methods]\n",
    "\n",
    "# Lista de números de neurônios escondidos para teste\n",
    "neurons_options = [3, 5, 7, 9]\n",
    "results = {}\n",
    "\n",
    "for k in neurons_options:\n",
    "    print(f\"\\nNúmero de neurônios escondidos: {k}\")\n",
    "    for rbf_func, std_method in configurations:\n",
    "        rbf_func_name = rbf_func.__name__\n",
    "        std_method_name = std_method.__name__\n",
    "\n",
    "        # Inicializa e treina a rede RBF\n",
    "        rbfnet = RBFNet(lr=1e-2, attnumber=attnumber, k=k, rbf=rbf_func, computeStds=std_method)\n",
    "        rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
    "\n",
    "        # Calcula a taxa de erro no conjunto de teste\n",
    "        test_labels_transformed = le.transform(test_labels.values)\n",
    "        y_pred = rbfnet.predict(test_inputs.values)\n",
    "\n",
    "        errorabs = abs(test_labels_transformed - y_pred)\n",
    "        error_rate = np.sum(errorabs) / len(test_labels_transformed)\n",
    "\n",
    "        # Exibe os resultados\n",
    "        print(f\"RBF: {rbf_func_name}, Método Largura: {std_method_name}, Taxa de erro: {error_rate:.4f}\")\n",
    "        results[(k, rbf_func_name, std_method_name)] = error_rate\n",
    "\n",
    "# Determina a melhor configuração\n",
    "best_config = min(results, key=results.get)\n",
    "print(\"\\nMelhor configuração encontrada:\")\n",
    "print(f\"Neurônios escondidos: {best_config[0]}\")\n",
    "print(f\"Função de Base Radial: {best_config[1]}\")\n",
    "print(f\"Método de Cálculo da Largura: {best_config[2]}\")\n",
    "print(f\"Taxa de erro: {results[best_config]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLO2Gq4Jtso3"
   },
   "source": [
    "# Descrição Mini Projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOrl4i0areNo"
   },
   "source": [
    "Utilizando o código acima, modifique a última seção (Executando com Base de Dados) para que ele seja executado com a base de dados do arquivo diabetes.csv. Depois, modifique a função de base radial implementada (Gaussiana) para a Multiquadrática Inversa e calcule a taxa de erro.\n",
    "\n",
    "\n",
    "1- Calcular a quantidade de neurônios escondidos:\n",
    "\n",
    "a) 3\n",
    "\n",
    "b) 5\n",
    "\n",
    "c) 7\n",
    "\n",
    "d) 9\n",
    "\n",
    "Qual foi a melhor configuração? Avaliaria um outro valor?\n",
    "\n",
    "R -> A melhor configuracao foi com 9 neuronios escondidos, com uma taxa de erro de 18,83%.\n",
    "\n",
    "2- Utilizando a melhor configuração da questão anterior, calcular a taxa de erro usando uma das outras maneiras de retorno da largura do campo receptivo da função de base radial, em que cada neurônio possui sua própria largura.\n",
    "\n",
    "R -> Taxa de erro com larguras individuais: 34,42%\n",
    "\n",
    "3- Calcular a taxa de erro combinando 2 funções de Base Radial e as duas maneiras de cálculo da largura do campo receptivo:\n",
    "\n",
    "a) Gaussiana\n",
    "\n",
    "b) Multiquadrática Inversa\n",
    "\n",
    "\n",
    "Qual foi a melhor configuração?\n",
    "\n",
    "R -> A melhor configuracao encontrada foi a rbfMultiquadratica como funcao de base radial, com 5 neuronios escondidos e usando o computeEqualStds como metodo de calculo de largura. A taxa de erro foi de 19,48%.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
